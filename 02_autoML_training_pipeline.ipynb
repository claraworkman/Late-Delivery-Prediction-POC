{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7fda1a",
   "metadata": {},
   "source": [
    "# AutoML Training - Late Delivery Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5af51",
   "metadata": {},
   "source": [
    "**Goal:** Train ML models to predict late deliveries using AutoML.\n",
    "\n",
    "This notebook will:\n",
    "1. Load closed delivery data from the semantic model\n",
    "2. Train **regression model** to predict AGE_REQ_DATE (days late/early)\n",
    "3. Create **classification model** for late vs on-time prediction\n",
    "4. Generate **lateness buckets** (0-2, 3-5, 6-9, 10+ days)\n",
    "5. Register best models to MLflow\n",
    "\n",
    "**Use Case:** Enable operations team to:\n",
    "- Identify deliveries at high risk of shipping late\n",
    "- Prioritize corrective actions for strategic accounts\n",
    "- Proactively communicate with business teams about potential delays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93410208",
   "metadata": {},
   "source": [
    "### â­ 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b71b7e",
   "metadata": {},
   "source": [
    "- pandas: dataframe manipulation\n",
    "- mlflow: experiment tracking and model registry\n",
    "- AutoML (FLAML): automatic model selection / tuning\n",
    "- sklearn: train/test split + evaluation metrics\n",
    "- sempy.fabric: read tables from Power BI semantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Experiment tracking\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Semantic Link - Connect to Power BI\n",
    "import sempy.fabric as fabric\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ… All libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ddeb0",
   "metadata": {},
   "source": [
    "### â­ 2. Configuration\n",
    "\n",
    "**IMPORTANT:** Update these settings for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad87ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic model name\n",
    "DATASET = \"DLV Aging Columns & Measures\"\n",
    "\n",
    "# Target variable: AGE_REQ_DATE (days late/early vs Customer Requested Delivery Date)\n",
    "# Positive = Late, Negative = Early, 0 = On-time\n",
    "TARGET_COLUMN = \"AGE_REQ_DATE\"\n",
    "\n",
    "# Model names for MLflow registry\n",
    "MODEL_NAME_REGRESSION = \"POC-LateDelivery-Regression-AutoML\"\n",
    "MODEL_NAME_CLASSIFICATION = \"POC-LateDelivery-Classification-AutoML\"\n",
    "\n",
    "# Workspace\n",
    "ws = fabric.get_workspace_id()\n",
    "\n",
    "print(f\"ðŸ“Š Semantic Model: {DATASET}\")\n",
    "print(f\"ðŸŽ¯ Target Variable: {TARGET_COLUMN}\")\n",
    "print(f\"ðŸ¤– Regression Model: {MODEL_NAME_REGRESSION}\")\n",
    "print(f\"ðŸ¤– Classification Model: {MODEL_NAME_CLASSIFICATION}\")\n",
    "print(f\"ðŸ¢ Workspace ID: {ws}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b9786",
   "metadata": {},
   "source": [
    "### â­ 3. Load Training Data Using DAX\n",
    "\n",
    "Load **closed deliveries** (with GI Date) for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAX query: Get closed deliveries (deliveries that have shipped)\n",
    "# Filter for deliveries with Goods Issue (GI) Date populated\n",
    "dax_query = \"\"\"\n",
    "EVALUATE\n",
    "FILTER(\n",
    "    Aging,\n",
    "    NOT(ISBLANK(Aging[GI Date]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute DAX query\n",
    "print(\"Loading closed delivery data from semantic model...\")\n",
    "df = fabric.evaluate_dax(dataset=DATASET, dax_string=dax_query, workspace=ws)\n",
    "\n",
    "# Clean column names (DAX adds table prefixes like 'Aging[column]')\n",
    "df.columns = [col.split('[')[-1].replace(']', '') if '[' in col else col for col in df.columns]\n",
    "\n",
    "print(f\"âœ… Loaded {len(df):,} closed deliveries\")\n",
    "print(f\"âœ… Columns: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print(f\"\\nFirst 20 column names:\")\n",
    "print(df.columns.tolist()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cf60b",
   "metadata": {},
   "source": [
    "### â­ 4. Data Quality Check & Filtering\n",
    "\n",
    "Remove rows with missing target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if target column exists\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    print(f\"âŒ ERROR: Target column '{TARGET_COLUMN}' not found in data!\")\n",
    "    print(f\"\\nAvailable columns:\")\n",
    "    print(df.columns.tolist())\n",
    "    raise ValueError(f\"Target column '{TARGET_COLUMN}' not found. Update TARGET_COLUMN variable.\")\n",
    "\n",
    "# Check for nulls in target\n",
    "print(f\"\\n=== Target Column: {TARGET_COLUMN} ===\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Null values: {df[TARGET_COLUMN].isnull().sum():,}\")\n",
    "print(f\"Non-null values: {df[TARGET_COLUMN].notna().sum():,}\")\n",
    "\n",
    "# Remove rows with null target\n",
    "df_clean = df[df[TARGET_COLUMN].notna()].copy()\n",
    "print(f\"\\nâœ… After removing nulls: {len(df_clean):,} rows\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\n=== Target Variable Statistics ===\")\n",
    "print(df_clean[TARGET_COLUMN].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5edd04",
   "metadata": {},
   "source": [
    "### â­ 5. Feature Selection\n",
    "\n",
    "Define features based on available columns in the Aging table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features based on actual Aging table schema\n",
    "# Updated to match the customer's semantic model columns\n",
    "\n",
    "potential_features = [\n",
    "    # Location & Routing\n",
    "    'Plant',                    # Distribution center\n",
    "    'Shipping Point',           # Shipping location\n",
    "    'EWM_CARRIER_CODE',         # Carrier code (important for performance)\n",
    "    \n",
    "    # Product Information\n",
    "    'Brand',                    # Calculated column (Callaway/Odyssey, Jack Wolfskin, etc.)\n",
    "    'Channel',                  # Calculated column (E-commerce, Inter-company, etc.)\n",
    "    'Product Category',         # Product category\n",
    "    'Product Type',             # Product type\n",
    "    'Standard Or Custom',       # Standard or custom product\n",
    "    \n",
    "    # Customer & Account\n",
    "    'STRATEGIC_ACCOUNT',        # Strategic vs non-strategic (KEY for prioritization!)\n",
    "    'Sold To - Key',            # Customer identifier\n",
    "    \n",
    "    # Delivery Attributes\n",
    "    'Delivery Type',            # Type of delivery\n",
    "    'DELIVERY_QTY',             # Quantity (numeric)\n",
    "    'DELIVERY_VALUE_USD',       # Value in USD (numeric)\n",
    "    'Delivery Priority',        # Priority level\n",
    "    'Shipping Condition',       # Shipping condition code\n",
    "    \n",
    "    # Processing Status\n",
    "    'Credit Status',            # Calculated column (Credit checked, Released, etc.)\n",
    "    'Distribution Status',      # Calculated column (Confirmed, Distributed, etc.)\n",
    "    'STATUS',                   # Delivery status\n",
    "]\n",
    "\n",
    "# Add temporal features from 'Delivery Created On' if it exists\n",
    "if 'Delivery Created On' in df_clean.columns:\n",
    "    try:\n",
    "        df_clean['created_dayofweek'] = pd.to_datetime(df_clean['Delivery Created On']).dt.dayofweek\n",
    "        df_clean['created_month'] = pd.to_datetime(df_clean['Delivery Created On']).dt.month\n",
    "        potential_features.extend(['created_dayofweek', 'created_month'])\n",
    "        print(\"âœ… Added temporal features (day of week, month)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not create temporal features: {e}\")\n",
    "\n",
    "# Filter to only features that exist in the dataframe\n",
    "feature_cols = [f for f in potential_features if f in df_clean.columns]\n",
    "\n",
    "print(f\"=== Feature Selection ===\")\n",
    "print(f\"Potential features: {len(potential_features)}\")\n",
    "print(f\"Available features: {len(feature_cols)}\")\n",
    "print(f\"\\nUsing features:\")\n",
    "for i, f in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {f}\")\n",
    "\n",
    "# Check for missing features\n",
    "missing_features = [f for f in potential_features if f not in df_clean.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\nâš ï¸  Missing features (not in data):\")\n",
    "    for f in missing_features:\n",
    "        print(f\"     - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b526eb",
   "metadata": {},
   "source": [
    "### â­ 6. Prepare Features + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X = df_clean[feature_cols].copy()\n",
    "y = df_clean[TARGET_COLUMN].copy()\n",
    "\n",
    "# Handle categorical variables - convert to numeric codes\n",
    "categorical_cols = X.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "\n",
    "print(f\"\\n=== Categorical Feature Encoding ===\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Fill NaN with a placeholder before encoding\n",
    "    X[col] = X[col].fillna('Unknown')\n",
    "    X[col] = X[col].astype(\"category\").cat.codes\n",
    "    print(f\"  âœ“ Encoded: {col}\")\n",
    "\n",
    "# Handle numeric NaNs\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        median_val = X[col].median()\n",
    "        X[col] = X[col].fillna(median_val)\n",
    "        print(f\"  âœ“ Filled NaNs in {col} with median: {median_val}\")\n",
    "\n",
    "print(f\"\\nâœ… Features: {X.shape[1]} columns, {X.shape[0]:,} rows\")\n",
    "print(f\"âœ… Target: {y.shape[0]:,} values\")\n",
    "print(f\"\\nFeature dtypes:\")\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcf5bb",
   "metadata": {},
   "source": [
    "### â­ 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe285f",
   "metadata": {},
   "source": [
    "Split into **training** (80%) and **test** (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training set: {X_train.shape[0]:,} rows\")\n",
    "print(f\"âœ… Test set: {X_test.shape[0]:,} rows\")\n",
    "print(f\"âœ… Features: {X_train.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e8bbd",
   "metadata": {},
   "source": [
    "### â­ 8. Train AutoML Model\n",
    "\n",
    "Using FLAML AutoML to find the best regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aafa3b",
   "metadata": {},
   "source": [
    "**AutoML Settings:**\n",
    "- **Time budget:** 180 seconds (3 minutes)\n",
    "- **Metric:** MAE (Mean Absolute Error)\n",
    "- **Models:** Random Forest, XGBoost, Extra Trees\n",
    "- **Task:** Regression (predicting numeric aging days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74002524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLflow experiment\n",
    "mlflow.set_experiment(\"AgingPrediction\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"automl_aging_prediction\") as run:\n",
    "    \n",
    "    # Configure AutoML\n",
    "    automl = AutoML()\n",
    "    \n",
    "    settings = {\n",
    "        \"time_budget\": 180,  # 3 minutes\n",
    "        \"metric\": \"mae\",\n",
    "        \"task\": \"regression\",\n",
    "        \"estimator_list\": [\"rf\", \"xgboost\", \"extra_tree\"],\n",
    "        \"log_file_name\": \"automl_aging.log\",\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params(settings)\n",
    "    \n",
    "    print(\"ðŸš€ Starting AutoML training...\")\n",
    "    print(f\"   Time budget: {settings['time_budget']} seconds\")\n",
    "    print(f\"   Metric: {settings['metric']}\")\n",
    "    print(f\"   Models: {settings['estimator_list']}\")\n",
    "    \n",
    "    # Train\n",
    "    automl.fit(X_train, y_train, **settings)\n",
    "    \n",
    "    print(f\"\\nâœ… Training complete!\")\n",
    "    print(f\"   Best model: {automl.best_estimator}\")\n",
    "    print(f\"   Best config: {automl.best_config}\")\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"\\nðŸ“Š MLflow Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7862f",
   "metadata": {},
   "source": [
    "### â­ 9. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3e5c6",
   "metadata": {},
   "source": [
    "Test the model on data it hasn't seen before.\n",
    "\n",
    "**Metrics:**\n",
    "- **MAE** (Mean Absolute Error): Average days off in predictions\n",
    "- **RMSE** (Root Mean Squared Error): Penalizes large errors more\n",
    "- **RÂ²** (R-squared): How much variance explained (0-1 scale)\n",
    "- **MAPE** (Mean Absolute Percentage Error): Average % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "preds = automl.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "mape = mean_absolute_percentage_error(y_test, preds) * 100\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(f\"MAE:  {mae:.3f} days  â† Average prediction error\")\n",
    "print(f\"RMSE: {rmse:.3f} days  â† Larger errors penalized more\")\n",
    "print(f\"RÂ²:   {r2:.3f}        â† Variance explained (higher is better)\")\n",
    "print(f\"MAPE: {mape:.2f}%      â† Average percentage error\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1091c84",
   "metadata": {},
   "source": [
    "### â­ 10. Register Model in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log metrics and register model\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"test_mae\", mae)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2)\n",
    "    mlflow.log_metric(\"test_mape\", mape)\n",
    "    \n",
    "    # Log feature names\n",
    "    mlflow.log_param(\"features\", \",\".join(feature_cols))\n",
    "    mlflow.log_param(\"num_features\", len(feature_cols))\n",
    "    mlflow.log_param(\"target_variable\", TARGET_COLUMN)\n",
    "    \n",
    "    # Register model\n",
    "    print(f\"\\nðŸ”„ Registering model: {MODEL_NAME}\")\n",
    "    \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=automl.model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Model registered successfully!\")\n",
    "    print(f\"   Model name: {MODEL_NAME}\")\n",
    "    print(f\"   Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b677af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target Variable: {TARGET_COLUMN}\")\n",
    "print(f\"Features Used: {len(feature_cols)}\")\n",
    "print(f\"Training Samples: {len(X_train):,}\")\n",
    "print(f\"Test Samples: {len(X_test):,}\")\n",
    "print(f\"\\nBest Model: {automl.best_estimator}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  MAE:  {mae:.3f} days\")\n",
    "print(f\"  RMSE: {rmse:.3f} days\")\n",
    "print(f\"  RÂ²:   {r2:.3f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "print(f\"\\nMLflow:\")\n",
    "print(f\"  Run ID: {run_id}\")\n",
    "print(f\"  Model Name: {MODEL_NAME}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb11b06",
   "metadata": {},
   "source": [
    "### â­ 11. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a20c16",
   "metadata": {},
   "source": [
    "#### Actual vs Predicted Scatter Plot\n",
    "\n",
    "Shows how well predictions match actual values.\n",
    "- Points on the diagonal line = perfect predictions\n",
    "- Points above line = model under-predicted (actual > predicted)\n",
    "- Points below line = model over-predicted (predicted > actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Actual vs Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, preds, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(f'Actual {TARGET_COLUMN} (days)', fontsize=12)\n",
    "plt.ylabel(f'Predicted {TARGET_COLUMN} (days)', fontsize=12)\n",
    "plt.title('Actual vs Predicted Aging Days', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"MAE: {mae:.2f} days | RMSE: {rmse:.2f} days | RÂ²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993c8ac",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "\n",
    "Shows which features have the most impact on predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281dc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if available)\n",
    "if hasattr(automl.model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': automl.model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['feature'][:15], importance_df['importance'][:15])\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.title('Top 15 Feature Importance', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"Feature importance not available for this model type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be816453",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Training Complete!\n",
    "\n",
    "The model has been trained and registered in MLflow.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Go to your Fabric workspace â†’ Experiments â†’ AgingPrediction\n",
    "2. View run details, metrics, and artifacts\n",
    "3. Proceed to **`03_batch_scoring_pipeline.ipynb`** to generate predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
