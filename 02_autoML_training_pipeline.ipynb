{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7fda1a",
   "metadata": {},
   "source": [
    "# AutoML Training - Late Delivery Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5af51",
   "metadata": {},
   "source": [
    "**Goal:** Train ML models to predict late deliveries using AutoML.\n",
    "\n",
    "This notebook will:\n",
    "1. Load closed delivery data from the semantic model\n",
    "2. Train **regression model** to predict AGE_REQ_DATE (days late/early)\n",
    "3. Create **classification model** for late vs on-time prediction\n",
    "4. Generate **lateness buckets** (0-2, 3-5, 6-9, 10+ days)\n",
    "5. Register best models to MLflow\n",
    "\n",
    "**Use Case:** Enable operations team to:\n",
    "- Identify deliveries at high risk of shipping late\n",
    "- Prioritize corrective actions for strategic accounts\n",
    "- Proactively communicate with business teams about potential delays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93410208",
   "metadata": {},
   "source": [
    "### ‚≠ê 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b71b7e",
   "metadata": {},
   "source": [
    "- pandas: dataframe manipulation\n",
    "- mlflow: experiment tracking and model registry\n",
    "- AutoML (FLAML): automatic model selection / tuning\n",
    "- sklearn: train/test split + evaluation metrics\n",
    "- sempy.fabric: read tables from Power BI semantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Experiment tracking\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Semantic Link - Connect to Power BI\n",
    "import sempy.fabric as fabric\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"‚úÖ All libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ddeb0",
   "metadata": {},
   "source": [
    "### ‚≠ê 2. Configuration\n",
    "\n",
    "**IMPORTANT:** Update these settings for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad87ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic model name\n",
    "DATASET = \"DLV Aging Columns & Measures\"\n",
    "\n",
    "# Target variable: AGE_REQ_DATE (days late/early vs Customer Requested Delivery Date)\n",
    "# Positive = Late, Negative = Early, 0 = On-time\n",
    "TARGET_COLUMN = \"AGE_REQ_DATE\"\n",
    "\n",
    "# Model names for MLflow registry\n",
    "MODEL_NAME_REGRESSION = \"POC-LateDelivery-Regression-AutoML\"\n",
    "MODEL_NAME_CLASSIFICATION = \"POC-LateDelivery-Classification-AutoML\"\n",
    "\n",
    "# Workspace\n",
    "ws = fabric.get_workspace_id()\n",
    "\n",
    "print(f\"üìä Semantic Model: {DATASET}\")\n",
    "print(f\"üéØ Target Variable: {TARGET_COLUMN}\")\n",
    "print(f\"ü§ñ Regression Model: {MODEL_NAME_REGRESSION}\")\n",
    "print(f\"ü§ñ Classification Model: {MODEL_NAME_CLASSIFICATION}\")\n",
    "print(f\"üè¢ Workspace ID: {ws}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b9786",
   "metadata": {},
   "source": [
    "### ‚≠ê 3. Load Training Data Using DAX\n",
    "\n",
    "Load **closed deliveries** (with GI Date) for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAX query: Get closed deliveries (deliveries that have shipped)\n",
    "# Filter for deliveries with Goods Issue (GI) Date populated\n",
    "dax_query = \"\"\"\n",
    "EVALUATE\n",
    "FILTER(\n",
    "    Aging,\n",
    "    NOT(ISBLANK(Aging[GI Date]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute DAX query\n",
    "print(\"Loading closed delivery data from semantic model...\")\n",
    "df = fabric.evaluate_dax(dataset=DATASET, dax_string=dax_query, workspace=ws)\n",
    "\n",
    "# Clean column names (DAX adds table prefixes like 'Aging[column]')\n",
    "df.columns = [col.split('[')[-1].replace(']', '') if '[' in col else col for col in df.columns]\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df):,} closed deliveries\")\n",
    "print(f\"‚úÖ Columns: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cf60b",
   "metadata": {},
   "source": [
    "### ‚≠ê 4. Data Quality Check & Filtering\n",
    "\n",
    "Remove rows with missing target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target column and remove nulls\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COLUMN}' not found!\")\n",
    "\n",
    "print(f\"Target: {TARGET_COLUMN}\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Null values: {df[TARGET_COLUMN].isnull().sum():,}\")\n",
    "\n",
    "# Remove rows with null target\n",
    "df_clean = df[df[TARGET_COLUMN].notna()].copy()\n",
    "print(f\"‚úÖ Clean dataset: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5edd04",
   "metadata": {},
   "source": [
    "### ‚≠ê 5. Feature Selection\n",
    "\n",
    "Define features based on available columns in the Aging table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features based on actual Aging table schema\n",
    "# Updated to match the customer's semantic model columns\n",
    "\n",
    "potential_features = [\n",
    "    # Location & Routing\n",
    "    'Plant',                    # Distribution center\n",
    "    'Shipping Point',           # Shipping location\n",
    "    'EWM Carrier Code',         # Carrier code (important for performance)\n",
    "    \n",
    "    # Product Information\n",
    "    'Brand',                    # Calculated column (Callaway/Odyssey, Jack Wolfskin, etc.)\n",
    "    'Channel',                  # Calculated column (E-commerce, Inter-company, etc.)\n",
    "    'Product Category',         # Product category\n",
    "    'Product Type',             # Product type\n",
    "    'Standard Or Custom',       # Standard or custom product\n",
    "    \n",
    "    # Customer & Account\n",
    "    'STRATEGIC_ACCOUNT',        # Strategic vs non-strategic (KEY for prioritization!)\n",
    "    'Sold To - Key',            # Customer identifier\n",
    "    \n",
    "    # Delivery Attributes\n",
    "    'Delivery Type',            # Type of delivery\n",
    "    'DELIVERY_QTY',             # Quantity (numeric)\n",
    "    'DELIVERY_VALUE_USD',       # Value in USD (numeric)\n",
    "    'Delivery Priority',        # Priority level\n",
    "    'Shipping Condition',       # Shipping condition code\n",
    "    \n",
    "    # Processing Status\n",
    "    'Credit Status',            # Calculated column (Credit checked, Released, etc.)\n",
    "    'Distribution Status',      # Calculated column (Confirmed, Distributed, etc.)\n",
    "    'STATUS',                   # Delivery status\n",
    "]\n",
    "\n",
    "# Add temporal features from 'Delivery Created On' if it exists\n",
    "if 'Delivery Created On' in df_clean.columns:\n",
    "    try:\n",
    "        df_clean['created_dayofweek'] = pd.to_datetime(df_clean['Delivery Created On']).dt.dayofweek\n",
    "        df_clean['created_month'] = pd.to_datetime(df_clean['Delivery Created On']).dt.month\n",
    "        potential_features.extend(['created_dayofweek', 'created_month'])\n",
    "        print(\"‚úÖ Added temporal features (day of week, month)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not create temporal features: {e}\")\n",
    "\n",
    "# Filter to only features that exist in the dataframe\n",
    "feature_cols = [f for f in potential_features if f in df_clean.columns]\n",
    "\n",
    "print(f\"=== Feature Selection ===\")\n",
    "print(f\"Potential features: {len(potential_features)}\")\n",
    "print(f\"Available features: {len(feature_cols)}\")\n",
    "print(f\"\\nUsing features:\")\n",
    "for i, f in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {f}\")\n",
    "\n",
    "# Check for missing features\n",
    "missing_features = [f for f in potential_features if f not in df_clean.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing features (not in data):\")\n",
    "    for f in missing_features:\n",
    "        print(f\"     - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b526eb",
   "metadata": {},
   "source": [
    "### ‚≠ê 6. Prepare Features + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X = df_clean[feature_cols].copy()\n",
    "y = df_clean[TARGET_COLUMN].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna('Unknown')\n",
    "    X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# Handle numeric NaNs\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f\"‚úÖ Features: {X.shape[1]} columns, {X.shape[0]:,} rows\")\n",
    "print(f\"‚úÖ Target: {y.shape[0]:,} values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcf5bb",
   "metadata": {},
   "source": [
    "### ‚≠ê 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training set: {X_train.shape[0]:,} rows\")\n",
    "print(f\"‚úÖ Test set: {X_test.shape[0]:,} rows\")\n",
    "print(f\"‚úÖ Features: {X_train.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e8bbd",
   "metadata": {},
   "source": [
    "### ‚≠ê 8. Train AutoML Model\n",
    "\n",
    "Using FLAML AutoML to find the best regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74002524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "settings = {\n",
    "    \"time_budget\": 180,  # 3 minutes\n",
    "    \"metric\": \"mae\",\n",
    "    \"task\": \"regression\",\n",
    "    \"estimator_list\": [\"rf\", \"xgboost\", \"extra_tree\"],\n",
    "    \"log_file_name\": \"automl.log\",\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "print(\"Starting AutoML training...\")\n",
    "print(f\"Time budget: {settings['time_budget']}s\")\n",
    "print(f\"Metric: {settings['metric']}\")\n",
    "\n",
    "# Train\n",
    "automl.fit(X_train, y_train, **settings)\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"Best model: {automl.best_estimator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7862f",
   "metadata": {},
   "source": [
    "### ‚≠ê 9. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "preds = automl.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(f\"MAE:  {mae:.2f} days\")\n",
    "print(f\"RMSE: {rmse:.2f} days\")\n",
    "print(f\"R¬≤:   {r2:.3f}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1091c84",
   "metadata": {},
   "source": [
    "### ‚≠ê 10. Register Model in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model in MLflow\n",
    "mlflow.set_experiment(\"Late_Delivery_Prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"automl_regression\") as run:\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"test_mae\", mae)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2)\n",
    "    \n",
    "    # Register model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=automl.model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=MODEL_NAME_REGRESSION\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model registered: {MODEL_NAME_REGRESSION}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b677af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME_REGRESSION}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Test MAE: {mae:.2f} days\")\n",
    "print(f\"Test R¬≤: {r2:.3f}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ Next: Open 03_batch_scoring_pipeline.ipynb\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be816453",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Training Complete!\n",
    "\n",
    "Proceed to **`03_batch_scoring_pipeline.ipynb`** to generate predictions for open deliveries."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
