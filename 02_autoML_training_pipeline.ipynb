{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7fda1a",
   "metadata": {},
   "source": [
    "# AutoML Training - Ship Date Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5af51",
   "metadata": {},
   "source": [
    "**Goal:** Train ML models to predict when orders will ship from the distribution center using AutoML.\n",
    "\n",
    "This notebook will:\n",
    "1. Load closed delivery data from the semantic model\n",
    "2. Calculate **DAYS_TO_SHIP** (days from creation to DC ship date)\n",
    "3. Train **regression model** to predict DAYS_TO_SHIP\n",
    "4. Register best model to MLflow\n",
    "5. Enable ship date forecasting for open deliveries\n",
    "\n",
    "**Use Case:** Enable operations team to:\n",
    "- Forecast when orders will ship from the distribution center\n",
    "- Plan logistics and inventory allocation\n",
    "- Set realistic customer expectations for ship dates\n",
    "- Identify orders with unusually long processing times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93410208",
   "metadata": {},
   "source": [
    "### ⭐ 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b71b7e",
   "metadata": {},
   "source": [
    "- pandas: dataframe manipulation\n",
    "- mlflow: experiment tracking and model registry\n",
    "- AutoML (FLAML): automatic model selection / tuning\n",
    "- sklearn: train/test split + evaluation metrics\n",
    "- sempy.fabric: read tables from Power BI semantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORTS & CONFIGURATION\n",
    "# ==============================================================================\n",
    "# WHY: Load required libraries for ML training and semantic model access\n",
    "#\n",
    "# Key libraries:\n",
    "# - sempy.fabric: Connect to Power BI semantic model\n",
    "# - flaml.AutoML: Microsoft's AutoML library (automatically tests multiple algorithms)\n",
    "# - mlflow: Track experiments and save models\n",
    "# - sklearn: Machine learning utilities (train/test split, metrics)\n",
    "# ==============================================================================\n",
    "\n",
    "import sempy.fabric as fabric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flaml import AutoML\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Configuration\n",
    "DATASET = \"DLV Aging\"  # UPDATE: Match your semantic model name\n",
    "TARGET_COLUMN = \"DAYS_TO_SHIP\"  # What we're predicting (days from creation to ship)\n",
    "\n",
    "# AutoML settings\n",
    "# WHY: These settings control how AutoML explores different models\n",
    "automl_settings = {\n",
    "    \"time_budget\": 600,      # Maximum 10 minutes for training (reduce if needed)\n",
    "    \"metric\": \"mae\",         # Optimize for Mean Absolute Error (avg days off)\n",
    "    \"task\": \"regression\",    # Predicting a number (days to ship), not a category\n",
    "    \"log_file_name\": \"automl.log\",\n",
    "    \"seed\": 42,              # For reproducible results\n",
    "    \"early_stop\": True,      # Stop if no improvement (saves time/capacity)\n",
    "}\n",
    "\n",
    "print(\"✅ Configuration loaded\")\n",
    "print(f\"   Target: {TARGET_COLUMN}\")\n",
    "print(f\"   AutoML budget: {automl_settings['time_budget']} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ddeb0",
   "metadata": {},
   "source": [
    "### ⭐ 2. Configuration\n",
    "\n",
    "**IMPORTANT:** Update these settings for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad87ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LOAD TRAINING DATA: Closed Deliveries\n",
    "# ==============================================================================\n",
    "# WHY: We need historical deliveries with known outcomes (shipped with GI Date)\n",
    "#      to train the model to recognize patterns in shipping lead times.\n",
    "#\n",
    "# FILTER: Only deliveries with both GI Date (ship date) AND Delivery Created On\n",
    "#         These are \"labeled data\" where we can calculate actual days to ship.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Loading closed delivery data from semantic model...\")\n",
    "\n",
    "# Get workspace\n",
    "ws = fabric.get_workspace_id()\n",
    "\n",
    "# DAX query to get closed deliveries with both required dates\n",
    "dax_query = \"\"\"\n",
    "EVALUATE\n",
    "FILTER(\n",
    "    Aging,\n",
    "    NOT(ISBLANK(Aging[GI Date])) &&\n",
    "    NOT(ISBLANK(Aging[Delivery Created On]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "df = fabric.evaluate_dax(dataset=DATASET, dax_string=dax_query, workspace=ws)\n",
    "\n",
    "# Clean column names (DAX adds table prefixes)\n",
    "df.columns = [col.split('[')[-1].replace(']', '') if '[' in col else col for col in df.columns]\n",
    "\n",
    "print(f\"✅ Loaded {len(df):,} closed deliveries\")\n",
    "print(f\"✅ Columns: {df.shape[1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b9786",
   "metadata": {},
   "source": [
    "### ⭐ 3. Load Training Data Using DAX\n",
    "\n",
    "Load **closed deliveries** (with GI Date) for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CALCULATE TARGET VARIABLE: DAYS_TO_SHIP\n",
    "# ==============================================================================\n",
    "# WHY: This is the metric we're predicting - how many days from order creation\n",
    "#      to shipping from the DC.\n",
    "#\n",
    "# Formula: DAYS_TO_SHIP = GI Date - Delivery Created On\n",
    "#\n",
    "# This represents the processing lead time within the distribution center.\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=== Calculating Target Variable ===\")\n",
    "\n",
    "# Check if required columns exist\n",
    "required_cols = ['GI Date', 'Delivery Created On']\n",
    "missing = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Calculate DAYS_TO_SHIP\n",
    "df[TARGET_COLUMN] = (\n",
    "    pd.to_datetime(df['GI Date']) - \n",
    "    pd.to_datetime(df['Delivery Created On'])\n",
    ").dt.days\n",
    "\n",
    "# Remove rows with missing target values\n",
    "df_clean = df.dropna(subset=[TARGET_COLUMN]).copy()\n",
    "print(f\"✅ Target column calculated: {TARGET_COLUMN}\")\n",
    "print(f\"✅ Valid rows: {len(df_clean):,} (removed {len(df) - len(df_clean):,} missing target)\")\n",
    "\n",
    "# Show target distribution\n",
    "print(f\"\\nTarget Variable Stats:\")\n",
    "print(f\"  Mean: {df_clean[TARGET_COLUMN].mean():.2f} days\")\n",
    "print(f\"  Median: {df_clean[TARGET_COLUMN].median():.2f} days\")\n",
    "print(f\"  Min: {df_clean[TARGET_COLUMN].min():.0f} days\")\n",
    "print(f\"  Max: {df_clean[TARGET_COLUMN].max():.0f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cf60b",
   "metadata": {},
   "source": [
    "### ⭐ 4. Data Quality Check & Filtering\n",
    "\n",
    "Remove rows with missing target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target column and remove nulls\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COLUMN}' not found!\")\n",
    "\n",
    "print(f\"Target: {TARGET_COLUMN}\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Null values: {df[TARGET_COLUMN].isnull().sum():,}\")\n",
    "\n",
    "# Remove rows with null target\n",
    "df_clean = df[df[TARGET_COLUMN].notna()].copy()\n",
    "print(f\"✅ Clean dataset: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5edd04",
   "metadata": {},
   "source": [
    "### ⭐ 5. Feature Selection\n",
    "\n",
    "Define features based on available columns in the Aging table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE SELECTION\n",
    "# ==============================================================================\n",
    "# WHY: Choose which columns (features) the model will use to predict ship time.\n",
    "#      More relevant features = better predictions.\n",
    "#\n",
    "# Features are the \"clues\" the model uses:\n",
    "# - Location: Plant, Shipping Point\n",
    "# - Logistics: Carrier, Delivery Type\n",
    "# - Product: Brand, Channel, Category\n",
    "# - Customer: Strategic Account flag\n",
    "# - Timing: Day of week, month created\n",
    "# ==============================================================================\n",
    "\n",
    "# Define potential features based on Aging table schema\n",
    "potential_features = [\n",
    "    # Location & Routing\n",
    "    'Plant',                    # Distribution center\n",
    "    'Shipping Point',           # Shipping location\n",
    "    'EWM Carrier Code',         # Carrier code (important for performance)\n",
    "    \n",
    "    # Product Information\n",
    "    'Brand',                    # Calculated column (Callaway/Odyssey, Jack Wolfskin, etc.)\n",
    "    'Channel',                  # Calculated column (E-commerce, Inter-company, etc.)\n",
    "    'Product Category',         # Product category\n",
    "    'Product Type',             # Product type\n",
    "    'Standard Or Custom',       # Standard or custom product\n",
    "    \n",
    "    # Customer & Account\n",
    "    'STRATEGIC_ACCOUNT',        # Strategic vs non-strategic (KEY for prioritization!)\n",
    "    'Sold To - Key',            # Customer identifier\n",
    "    \n",
    "    # Delivery Attributes\n",
    "    'Delivery Type',            # Type of delivery\n",
    "    'DELIVERY_QTY',             # Quantity (numeric)\n",
    "    'DELIVERY_VALUE_USD',       # Value in USD (numeric)\n",
    "    'Delivery Priority',        # Priority level\n",
    "    'Shipping Condition',       # Shipping condition code\n",
    "    \n",
    "    # Processing Status\n",
    "    'Credit Status',            # Calculated column (Credit checked, Released, etc.)\n",
    "    'Distribution Status',      # Calculated column (Confirmed, Distributed, etc.)\n",
    "    'STATUS',                   # Delivery status\n",
    "]\n",
    "\n",
    "# Add temporal features from 'Delivery Created On' if it exists\n",
    "# WHY: Deliveries created on certain days/months may have different processing times\n",
    "if 'Delivery Created On' in df_clean.columns:\n",
    "    try:\n",
    "        df_clean['created_dayofweek'] = pd.to_datetime(df_clean['Delivery Created On']).dt.dayofweek\n",
    "        df_clean['created_month'] = pd.to_datetime(df_clean['Delivery Created On']).dt.month\n",
    "        potential_features.extend(['created_dayofweek', 'created_month'])\n",
    "        print(\"✅ Added temporal features (day of week, month)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not create temporal features: {e}\")\n",
    "\n",
    "# Filter to only features that exist in the dataframe\n",
    "feature_cols = [f for f in potential_features if f in df_clean.columns]\n",
    "\n",
    "print(f\"=== Feature Selection ===\")\n",
    "print(f\"Potential features: {len(potential_features)}\")\n",
    "print(f\"Available features: {len(feature_cols)}\")\n",
    "print(f\"\\nUsing features:\")\n",
    "for i, f in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {f}\")\n",
    "\n",
    "# Check for missing features\n",
    "missing_features = [f for f in potential_features if f not in df_clean.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\n⚠️  Missing features (not in data):\")\n",
    "    for f in missing_features:\n",
    "        print(f\"     - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b526eb",
   "metadata": {},
   "source": [
    "### ⭐ 6. Prepare Features + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X = df_clean[feature_cols].copy()\n",
    "y = df_clean[TARGET_COLUMN].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = X.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna('Unknown')\n",
    "    X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# Handle numeric NaNs\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f\"✅ Features: {X.shape[1]} columns, {X.shape[0]:,} rows\")\n",
    "print(f\"✅ Target: {y.shape[0]:,} values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcf5bb",
   "metadata": {},
   "source": [
    "### ⭐ 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE ENCODING: Convert Text to Numbers\n",
    "# ==============================================================================\n",
    "# WHY: Machine learning models only understand numbers, not text.\n",
    "#      We need to convert text like \"FedEx\" or \"US01\" into numeric codes.\n",
    "#\n",
    "# Process:\n",
    "# 1. Text columns → Convert to category codes (FedEx=0, UPS=1, DHL=2, etc.)\n",
    "# 2. Missing text → Fill with \"Unknown\" first\n",
    "# 3. Numeric columns → Fill missing values with median (middle value)\n",
    "# ==============================================================================\n",
    "\n",
    "# Extract features and target\n",
    "X = df_clean[feature_cols].copy()  # Input features\n",
    "y = df_clean[TARGET_COLUMN].copy()  # Output to predict\n",
    "\n",
    "# Encode categorical variables (text → numbers)\n",
    "categorical_cols = X.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna('Unknown')  # Fill missing text with \"Unknown\"\n",
    "    X[col] = X[col].astype(\"category\").cat.codes  # Convert to numeric codes\n",
    "\n",
    "# Handle numeric NaNs (fill with median)\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f\"✅ Features: {X.shape[1]} columns, {X.shape[0]:,} rows\")\n",
    "print(f\"✅ Target: {y.shape[0]:,} values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e8bbd",
   "metadata": {},
   "source": [
    "### ⭐ 8. Train AutoML Model\n",
    "\n",
    "Using FLAML AutoML to find the best regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74002524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# ==============================================================================\n",
    "# WHY: Split data into two parts:\n",
    "#      1. Training set (80%): Teaches the model patterns\n",
    "#      2. Test set (20%): Validates how well it learned (unseen data)\n",
    "#\n",
    "# This prevents \"overfitting\" - memorizing training data vs learning patterns.\n",
    "# ==============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42     # Reproducible split\n",
    ")\n",
    "\n",
    "print(f\"=== Train/Test Split ===\")\n",
    "print(f\"Training set:   {len(X_train):,} rows ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set:       {len(X_test):,} rows ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"Features:       {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7862f",
   "metadata": {},
   "source": [
    "### ⭐ 9. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EVALUATE MODEL PERFORMANCE\n",
    "# ==============================================================================\n",
    "# WHY: Test the model on unseen data to see how accurate predictions are.\n",
    "#\n",
    "# Metrics explained:\n",
    "# - MAE (Mean Absolute Error): Average days the prediction is off\n",
    "#   Example: MAE=2 means predictions are typically ±2 days off\n",
    "#\n",
    "# - RMSE (Root Mean Squared Error): Penalizes large errors more\n",
    "#   Useful for catching predictions that are WAY off\n",
    "#\n",
    "# - R² (R-squared): How well the model explains variance (0-1 scale)\n",
    "#   0.5 = 50% of variance explained, 0.8 = 80% (good), 0.95 = 95% (excellent)\n",
    "# ==============================================================================\n",
    "\n",
    "# Make predictions on test set (unseen data)\n",
    "preds = automl.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(\"\\n=== MODEL PERFORMANCE ON TEST SET ===\")\n",
    "print(f\"MAE:  {mae:.2f} days (avg prediction error)\")\n",
    "print(f\"RMSE: {rmse:.2f} days (penalizes large errors)\")\n",
    "print(f\"R²:   {r2:.3f} (variance explained: {r2*100:.1f}%)\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Interpretation guide\n",
    "if mae < 2:\n",
    "    print(\"✅ Excellent accuracy (< 2 days error)\")\n",
    "elif mae < 3:\n",
    "    print(\"✅ Good accuracy (2-3 days error)\")\n",
    "elif mae < 5:\n",
    "    print(\"⚠️ Moderate accuracy (3-5 days error)\")\n",
    "else:\n",
    "    print(\"⚠️ Consider adding more features or data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1091c84",
   "metadata": {},
   "source": [
    "### ⭐ 10. Register Model in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# REGISTER MODEL IN MLFLOW\n",
    "# ==============================================================================\n",
    "# WHY: MLflow stores the trained model so Notebook 03 can load it for scoring.\n",
    "#      It also tracks experiments, metrics, and model versions.\n",
    "#\n",
    "# What gets saved:\n",
    "# - The trained model (algorithm + learned parameters)\n",
    "# - Performance metrics (MAE, RMSE, R²)\n",
    "# - Model version history\n",
    "#\n",
    "# Model name: \"ship_date_predictor\" - used in Notebook 03 to load model\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n=== Registering Model in MLflow ===\")\n",
    "\n",
    "mlflow.set_experiment(\"Ship_Date_Prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"automl_regression\") as run:\n",
    "    # Log performance metrics\n",
    "    mlflow.log_metric(\"test_mae\", mae)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2)\n",
    "    \n",
    "    # Register the trained model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=automl.model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=MODEL_NAME_REGRESSION\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Model registered: {MODEL_NAME_REGRESSION}\")\n",
    "    print(f\"✅ Run ID: {run.info.run_id}\")\n",
    "    print(f\"✅ Metrics logged: MAE={mae:.2f}, RMSE={rmse:.2f}, R²={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bfd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# AUTOML TRAINING\n",
    "# ==============================================================================\n",
    "# WHY: AutoML automatically tests multiple algorithms and finds the best one.\n",
    "#      It's like having a data scientist test Random Forest, XGBoost, \n",
    "#      Linear Regression, etc. and pick the winner.\n",
    "#\n",
    "# What AutoML does:\n",
    "# 1. Tests different algorithms (Random Forest, Gradient Boosting, etc.)\n",
    "# 2. Tunes hyperparameters (tree depth, learning rate, etc.)\n",
    "# 3. Validates each model\n",
    "# 4. Returns the best performer\n",
    "#\n",
    "# Time budget: 600 seconds (10 min) - reduce if capacity is tight\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING AUTOML TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"This will test multiple algorithms and find the best model...\")\n",
    "print(f\"Time budget: {automl_settings['time_budget']} seconds\")\n",
    "print(f\"Training on: {len(X_train):,} deliveries\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Initialize AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "# Train (this takes 5-10 minutes)\n",
    "automl.fit(X_train, y_train, **automl_settings)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best model: {automl.best_estimator}\")\n",
    "print(f\"Best validation score (MAE): {automl.best_loss:.2f} days\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model name for MLflow registration\n",
    "MODEL_NAME_REGRESSION = \"ship_date_predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b677af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_NAME_REGRESSION}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Test MAE: {mae:.2f} days\")\n",
    "print(f\"\\nThis model predicts DAYS_TO_SHIP (days from creation to DC ship)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNEXT: Open 03_batch_scoring_pipeline.ipynb to score open deliveries\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be816453",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Training Complete!\n",
    "\n",
    "Proceed to **`03_batch_scoring_pipeline.ipynb`** to generate predictions for open deliveries."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
