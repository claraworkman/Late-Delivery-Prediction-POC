{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649cec3d",
   "metadata": {},
   "source": [
    "# Batch Scoring Pipeline - Late Delivery Predictions for Open Deliveries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc91028",
   "metadata": {},
   "source": [
    "**Goal:** Generate late delivery risk predictions for **open deliveries** (not yet shipped).\n",
    "\n",
    "**Use Case:** Enable operations team to:\n",
    "- Identify deliveries at high risk of shipping late\n",
    "- Prioritize corrective actions for strategic accounts\n",
    "- Proactively communicate with business teams about potential delays\n",
    "\n",
    "**Workflow:**\n",
    "1. Load trained regression model from MLflow\n",
    "2. Get **open deliveries** using DAX (deliveries without GI Date)\n",
    "3. Generate predictions: days late + risk score + lateness bucket\n",
    "4. Save predictions to Lakehouse table: `late_delivery_predictions`\n",
    "5. Visualize high-risk deliveries\n",
    "6. Enable Power BI reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeba6fc",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model loading\n",
    "import mlflow\n",
    "\n",
    "# Semantic Link - Connect to Power BI\n",
    "import sempy.fabric as fabric\n",
    "\n",
    "# Spark for writing to Lakehouse\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ… All libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78817577",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic model name\n",
    "DATASET = \"DLV Aging Columns & Measures\"\n",
    "\n",
    "# MLflow model details\n",
    "MODEL_NAME = \"POC-LateDelivery-Regression-AutoML\"\n",
    "MODEL_VERSION = \"latest\"  # or specify version like \"1\", \"2\", etc.\n",
    "\n",
    "# Target variable (must match training notebook)\n",
    "TARGET_COLUMN = \"AGE_REQ_DATE\"\n",
    "\n",
    "# Output table name\n",
    "OUTPUT_TABLE = \"late_delivery_predictions\"\n",
    "\n",
    "# Workspace\n",
    "ws = fabric.get_workspace_id()\n",
    "\n",
    "print(f\"ğŸ“Š Dataset: {DATASET}\")\n",
    "print(f\"ğŸ¤– Model: {MODEL_NAME}\")\n",
    "print(f\"ğŸ“Œ Version: {MODEL_VERSION}\")\n",
    "print(f\"ğŸ¯ Target: {TARGET_COLUMN}\")\n",
    "print(f\"ğŸ’¾ Output Table: {OUTPUT_TABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ef4e4",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 3. Load Trained Model from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from MLflow registry\n",
    "model_uri = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\n",
    "\n",
    "print(f\"Loading model from: {model_uri}\")\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(f\"âœ… Model loaded successfully!\")\n",
    "print(f\"   Model type: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ecf66",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 4. Load Open Deliveries from Semantic Model\n",
    "\n",
    "Load **only open deliveries** (not yet shipped) that need predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335656b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load open deliveries (no GI Date = not shipped yet)\n",
    "dax_query = \"\"\"\n",
    "EVALUATE\n",
    "FILTER(\n",
    "    Aging,\n",
    "    ISBLANK(Aging[GI Date])\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Loading open deliveries...\")\n",
    "df_open = fabric.evaluate_dax(dataset=DATASET, dax_string=dax_query, workspace=ws)\n",
    "\n",
    "# Clean column names\n",
    "df_open.columns = [col.split('[')[-1].replace(']', '') if '[' in col else col for col in df_open.columns]\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_open):,} open deliveries\")\n",
    "df_open.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b0dda",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 5. Prepare Features\n",
    "\n",
    "Extract the same features used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714836e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (must match training notebook)\n",
    "potential_features = [\n",
    "    'Plant', 'Shipping Point', 'EWM Carrier Code',\n",
    "    'Brand', 'Channel', 'Product Category', 'Product Type', 'Standard Or Custom',\n",
    "    'STRATEGIC_ACCOUNT', 'Sold To - Key',\n",
    "    'Delivery Type', 'DELIVERY_QTY', 'DELIVERY_VALUE_USD', 'Delivery Priority', 'Shipping Condition',\n",
    "    'Credit Status', 'Distribution Status', 'STATUS'\n",
    "]\n",
    "\n",
    "# Add temporal features\n",
    "if 'Delivery Created On' in df_open.columns:\n",
    "    try:\n",
    "        df_open['created_dayofweek'] = pd.to_datetime(df_open['Delivery Created On']).dt.dayofweek\n",
    "        df_open['created_month'] = pd.to_datetime(df_open['Delivery Created On']).dt.month\n",
    "        potential_features.extend(['created_dayofweek', 'created_month'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Filter to available features\n",
    "feature_cols = [f for f in potential_features if f in df_open.columns]\n",
    "print(f\"âœ… Using {len(feature_cols)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6b45f",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 6. Feature Engineering\n",
    "\n",
    "Apply the same transformations used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "X = df_open[feature_cols].copy()\n",
    "\n",
    "# Encode categoricals\n",
    "categorical_cols = X.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna('Unknown')\n",
    "    X[col] = X[col].astype(\"category\").cat.codes\n",
    "\n",
    "# Fill numeric NaNs\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f\"âœ… Features prepared: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b77c30",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 7. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predicted_days_late = model.predict(X)\n",
    "\n",
    "print(f\"âœ… Generated {len(predicted_days_late):,} predictions\")\n",
    "print(f\"Mean predicted days late: {predicted_days_late.mean():.2f}\")\n",
    "print(f\"Late deliveries predicted: {(predicted_days_late > 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87327e",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 8. Create Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b63c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dataframe\n",
    "from datetime import datetime\n",
    "\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "# Add delivery number\n",
    "if 'Delivery Number' in df_open.columns:\n",
    "    output_df['Delivery_Number'] = df_open['Delivery Number']\n",
    "\n",
    "# Add key business columns\n",
    "key_columns = ['Plant', 'Brand', 'Channel', 'Product Category', 'STRATEGIC_ACCOUNT',\n",
    "               'DELIVERY_QTY', 'DELIVERY_VALUE_USD', 'STATUS']\n",
    "\n",
    "for col in key_columns:\n",
    "    if col in df_open.columns:\n",
    "        output_df[col.replace(' ', '_')] = df_open[col]\n",
    "\n",
    "# Add predictions\n",
    "output_df['predicted_days_late'] = predicted_days_late\n",
    "output_df['is_late'] = (predicted_days_late > 0).astype(int)\n",
    "\n",
    "# Add lateness buckets\n",
    "def bucket_lateness(days):\n",
    "    if days <= 0: return 'On-time/Early'\n",
    "    elif days <= 2: return '0-2 days late'\n",
    "    elif days <= 5: return '3-5 days late'\n",
    "    elif days <= 9: return '6-9 days late'\n",
    "    else: return '10+ days late'\n",
    "\n",
    "output_df['lateness_bucket'] = predicted_days_late.apply(bucket_lateness)\n",
    "\n",
    "# Add risk score (0-1)\n",
    "max_late = predicted_days_late.max()\n",
    "min_late = predicted_days_late.min()\n",
    "output_df['risk_score'] = ((predicted_days_late - min_late) / (max_late - min_late)).clip(0, 1)\n",
    "\n",
    "# Add metadata\n",
    "output_df['prediction_date'] = datetime.now()\n",
    "output_df['model_name'] = MODEL_NAME\n",
    "\n",
    "print(f\"âœ… Output created: {len(output_df):,} rows, {output_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8376de0",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 9. Save Predictions to Lakehouse\n",
    "\n",
    "Write predictions to a Delta table for Power BI consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Lakehouse\n",
    "spark_df = spark.createDataFrame(output_df)\n",
    "\n",
    "print(f\"ğŸ’¾ Writing to Lakehouse table: {OUTPUT_TABLE}\")\n",
    "\n",
    "spark_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(OUTPUT_TABLE)\n",
    "\n",
    "print(f\"âœ… Saved {len(output_df):,} predictions\")\n",
    "print(f\"   Predicted LATE: {output_df['is_late'].sum():,}\")\n",
    "print(f\"   Predicted ON-TIME: {(~output_df['is_late'].astype(bool)).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd2e79",
   "metadata": {},
   "source": [
    "### ğŸŸ¦ 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SCORING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Bucket summary\n",
    "print(\"\\nğŸ“¦ Lateness Buckets:\")\n",
    "print(output_df['lateness_bucket'].value_counts().sort_index())\n",
    "\n",
    "# Top 10 high risk\n",
    "print(\"\\nğŸš¨ TOP 10 HIGHEST RISK:\")\n",
    "top_risk = output_df.nlargest(10, 'risk_score')[\n",
    "    ['Delivery_Number', 'Brand', 'STRATEGIC_ACCOUNT', \n",
    "     'predicted_days_late', 'lateness_bucket', 'risk_score']\n",
    "]\n",
    "print(top_risk.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ… Table '{OUTPUT_TABLE}' ready for Power BI\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53bc69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Predictions Complete!\n",
    "\n",
    "The `late_delivery_predictions` table is now available in your Lakehouse and can be used in Power BI for reporting and dashboards."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
