{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48bd0d2f",
   "metadata": {},
   "source": [
    "# ðŸ”® AGE_REQ_DATE Prediction Pipeline - Lateness Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2da908",
   "metadata": {},
   "source": [
    "**Goal:** Generate AGE_REQ_DATE (lateness) predictions for **open deliveries** (not yet shipped).\n",
    "\n",
    "**Use Case:** Enable operations team to:\n",
    "- Predict which orders will be late vs customer requested date\n",
    "- Proactively contact customers about at-risk deliveries\n",
    "- Prioritize strategic accounts with predicted late deliveries\n",
    "- Identify patterns in lateness by carrier, plant, customer\n",
    "\n",
    "**What is AGE_REQ_DATE?**\n",
    "- **AGE_REQ_DATE** = GI Date - Req. Date Header (Customer Requested Delivery Date)\n",
    "- **Positive values** = Late (shipped after customer requested date)\n",
    "- **Negative values** = Early (shipped before customer requested date)\n",
    "- **Zero** = On-time (shipped on customer requested date)\n",
    "\n",
    "**Example:**\n",
    "- Customer requests delivery by Nov 15\n",
    "- Predicted AGE_REQ_DATE = +3 days\n",
    "- Predicted ship date = Nov 18 (3 days late)\n",
    "\n",
    "**Workflow:**\n",
    "1. Load trained regression model from MLflow\n",
    "2. Get **open deliveries** using DAX (deliveries without GI Date)\n",
    "3. Generate AGE_REQ_DATE predictions\n",
    "4. Calculate predicted ship date: Req. Date Header + predicted AGE_REQ_DATE\n",
    "5. Categorize lateness and flag at-risk orders\n",
    "6. Save predictions to Lakehouse table: `delivery_lateness_predictions`\n",
    "7. View summary statistics and at-risk metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d6256",
   "metadata": {},
   "source": [
    "### ðŸ“¦ 1. Import Libraries & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORTS & CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "import sempy.fabric as fabric\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "DATASET = \"DLV Aging Columns & Measures\"  # UPDATE to match your semantic model name\n",
    "MODEL_NAME = \"ship_date_predictor\"  # Trained on AGE_REQ_DATE\n",
    "TARGET_COLUMN = \"AGE_REQ_DATE\"\n",
    "\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"   Semantic Model: {DATASET}\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   Target: {TARGET_COLUMN} (lateness vs customer requested date)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd7b48",
   "metadata": {},
   "source": [
    "### ðŸ¤– 2. Load Trained Model from MLflow\n",
    "\n",
    "**What's happening:** Load the AGE_REQ_DATE regression model you trained in Notebook 02. This model learned patterns from historical closed deliveries to predict how many days late/early future orders will be.\n",
    "\n",
    "**Key Details:**\n",
    "- Model name: `ship_date_predictor`\n",
    "- Trained on: AGE_REQ_DATE (GI Date - Req. Date Header)\n",
    "- Performance: MAE ~0.63 days (very accurate!)\n",
    "- Registry: MLflow automatically tracks versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249da7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LOAD MODEL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Loading trained model from MLflow...\")\n",
    "\n",
    "model_uri = f\"models:/{MODEL_NAME}/latest\"\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(f\"âœ… Model loaded: {MODEL_NAME}\")\n",
    "print(f\"   Type: {type(model).__name__}\")\n",
    "print(f\"   URI: {model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed40e1",
   "metadata": {},
   "source": [
    "### ðŸ“¥ 3. Load Open Deliveries from Semantic Model\n",
    "\n",
    "**What's happening:** Query your Power BI semantic model for all deliveries that haven't shipped yet (blank GI Date). These are the orders we need to predict lateness for.\n",
    "\n",
    "**Filters Applied:**\n",
    "- âœ… GI Date is blank (not shipped yet)\n",
    "- âœ… Delivery Created On exists (valid order)\n",
    "- âœ… Req. Date Header exists (customer requested delivery date available)\n",
    "\n",
    "**Why this matters:** We can only predict lateness if we know when the customer wants the order. Without Req. Date Header, we can't calculate AGE_REQ_DATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LOAD OPEN DELIVERIES\n",
    "# ==============================================================================\n",
    "# WHY: Get all deliveries that haven't shipped yet (GI Date is blank)\n",
    "#      These are the orders we need to predict lateness for\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Loading open deliveries from semantic model...\")\n",
    "\n",
    "ws = fabric.get_workspace_id()\n",
    "\n",
    "dax_query = \"\"\"\n",
    "EVALUATE\n",
    "FILTER(\n",
    "    Aging,\n",
    "    ISBLANK(Aging[GI Date]) &&\n",
    "    NOT(ISBLANK(Aging[Delivery Created On])) &&\n",
    "    NOT(ISBLANK(Aging[Req. Date Header]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "df_open = fabric.evaluate_dax(dataset=DATASET, dax_string=dax_query, workspace=ws)\n",
    "\n",
    "# Clean column names\n",
    "df_open.columns = [col.split('[')[-1].replace(']', '') if '[' in col else col for col in df_open.columns]\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_open):,} open deliveries\")\n",
    "print(f\"   Columns: {len(df_open.columns)}\")\n",
    "print(f\"\\nðŸ“Š Sample data:\")\n",
    "df_open.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3a92c",
   "metadata": {},
   "source": [
    "### ðŸ”§ 4. Prepare Features for Scoring\n",
    "\n",
    "**CRITICAL:** Features must exactly match what the model was trained on!\n",
    "\n",
    "**The 7 Key Features:**\n",
    "1. Channel (e.g., Retail, Wholesale, Direct)\n",
    "2. Delivery Priority (e.g., High, Normal, Low)\n",
    "3. EWM Shipping Condition\n",
    "4. Shipping Point (which DC/warehouse)\n",
    "5. Sold To Name 1 (customer name - most important feature!)\n",
    "6. Standard Or Custom (product type)\n",
    "7. Product Category\n",
    "\n",
    "**Data Transformation:**\n",
    "- Categorical variables â†’ numeric codes (model can't read text)\n",
    "- Missing values â†’ filled with \"Unknown\" or median\n",
    "- Same encoding method used in training (consistency is key!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785da621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE PREPARATION\n",
    "# ==============================================================================\n",
    "# CRITICAL: Must match the exact features used during training!\n",
    "# ==============================================================================\n",
    "\n",
    "# Features used during training (UPDATE to match your training notebook)\n",
    "feature_cols = [\n",
    "    \"Channel\",\n",
    "    \"Delivery Priority\",\n",
    "    \"EWM Shipping Condition\",\n",
    "    \"Shipping Point\",\n",
    "    \"Sold To Name 1\",\n",
    "    \"Standard Or Custom\",\n",
    "    \"Product Category\"\n",
    "]\n",
    "\n",
    "# Filter to available features\n",
    "available_features = [f for f in feature_cols if f in df_open.columns]\n",
    "\n",
    "print(f\"=== Feature Matching ===\")\n",
    "print(f\"Expected features: {len(feature_cols)}\")\n",
    "print(f\"Available features: {len(available_features)}\")\n",
    "\n",
    "if len(available_features) < len(feature_cols):\n",
    "    missing = [f for f in feature_cols if f not in df_open.columns]\n",
    "    print(f\"âš ï¸ Missing features: {missing}\")\n",
    "\n",
    "# Extract features\n",
    "X_open = df_open[available_features].copy()\n",
    "\n",
    "# Encode categorical variables (same as training)\n",
    "categorical_cols = X_open.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    X_open[col] = X_open[col].fillna('Unknown')\n",
    "    X_open[col] = X_open[col].astype('category').cat.codes\n",
    "\n",
    "# Handle numeric NaNs\n",
    "numeric_cols = X_open.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if X_open[col].isnull().sum() > 0:\n",
    "        X_open[col] = X_open[col].fillna(X_open[col].median())\n",
    "\n",
    "print(f\"\\nâœ… Prepared {len(X_open):,} records for scoring\")\n",
    "print(f\"   Features: {len(available_features)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c94567f",
   "metadata": {},
   "source": [
    "### ðŸ”® 5. Generate AGE_REQ_DATE Predictions\n",
    "\n",
    "**What the model predicts:** How many days late/early each delivery will be compared to the customer's requested delivery date.\n",
    "\n",
    "**Interpreting Predictions:**\n",
    "- **+5.2 days** = Will ship 5.2 days AFTER customer requested date (LATE)\n",
    "- **-1.3 days** = Will ship 1.3 days BEFORE customer requested date (EARLY)\n",
    "- **0 days** = Will ship exactly on customer requested date (ON-TIME)\n",
    "\n",
    "**Accuracy:** Model is typically accurate within Â±0.63 days based on test performance. Most predictions will be very close to actual outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GENERATE PREDICTIONS\n",
    "# ==============================================================================\n",
    "# WHAT: Model predicts AGE_REQ_DATE (days late/early vs customer request)\n",
    "#       Positive = Late, Negative = Early, 0 = On-time\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING AGE_REQ_DATE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_open)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df_open['predicted_age_req_date'] = predictions\n",
    "\n",
    "print(f\"âœ… Generated {len(predictions):,} predictions\")\n",
    "print(f\"\\nðŸ“Š Prediction Statistics:\")\n",
    "print(f\"   Mean:   {predictions.mean():.2f} days\")\n",
    "print(f\"   Median: {np.median(predictions):.2f} days\")\n",
    "print(f\"   Min:    {predictions.min():.2f} days (early)\")\n",
    "print(f\"   Max:    {predictions.max():.2f} days (late)\")\n",
    "print(f\"   Std:    {predictions.std():.2f} days\")\n",
    "print(f\"\\nðŸ“ˆ Distribution:\")\n",
    "print(f\"   Predicted Early (<0):    {(predictions < 0).sum():,} ({(predictions < 0).sum()/len(predictions)*100:.1f}%)\")\n",
    "print(f\"   Predicted On-Time (0):   {(predictions == 0).sum():,} ({(predictions == 0).sum()/len(predictions)*100:.1f}%)\")\n",
    "print(f\"   Predicted Late (>0):     {(predictions > 0).sum():,} ({(predictions > 0).sum()/len(predictions)*100:.1f}%)\")\n",
    "print(f\"   Predicted Very Late (>5): {(predictions > 5).sum():,} ({(predictions > 5).sum()/len(predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be561413",
   "metadata": {},
   "source": [
    "### ðŸ“… 6. Calculate Predicted Ship Date\n",
    "\n",
    "Calculate when each delivery will actually ship by adding the predicted lateness to the customer's requested date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CALCULATE PREDICTED SHIP DATE\n",
    "# ==============================================================================\n",
    "# predicted_ship_date = Req. Date Header + predicted_age_req_date\n",
    "# ==============================================================================\n",
    "\n",
    "df_open['predicted_ship_date'] = (\n",
    "    pd.to_datetime(df_open['Req. Date Header']) + \n",
    "    pd.to_timedelta(df_open['predicted_age_req_date'], unit='d')\n",
    ")\n",
    "\n",
    "print(\"âœ… Calculated predicted ship dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e17d2",
   "metadata": {},
   "source": [
    "### ðŸ·ï¸ 7. Categorize Predictions & Flag At-Risk Orders\n",
    "\n",
    "**Business-Friendly Categories:**\n",
    "- ðŸŸ¢ **Early** - Shipped before customer requested date\n",
    "- ðŸŸ¡ **On-Time** - Within 3 days of customer requested date\n",
    "- ðŸ”´ **Late** - More than 3 days after customer requested date\n",
    "\n",
    "**At-Risk Flags:**\n",
    "- `at_risk` = TRUE if predicted >3 days late (action required)\n",
    "\n",
    "**Use Case:** Operations team can filter to at-risk orders each morning and proactively contact customers before issues escalate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e230f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CATEGORIZE LATENESS\n",
    "# ==============================================================================\n",
    "\n",
    "def categorize_lateness(days):\n",
    "    \"\"\"Categorize predicted AGE_REQ_DATE into simple buckets\"\"\"\n",
    "    if pd.isna(days):\n",
    "        return \"Unknown\"\n",
    "    elif days < 0:\n",
    "        return \"Early\"\n",
    "    elif days <= 3:\n",
    "        return \"On-Time\"\n",
    "    else:\n",
    "        return \"Late\"\n",
    "\n",
    "df_open['lateness_category'] = df_open['predicted_age_req_date'].apply(categorize_lateness)\n",
    "\n",
    "# Flag at-risk deliveries (predicted >3 days late)\n",
    "df_open['at_risk'] = df_open['predicted_age_req_date'] > 3\n",
    "\n",
    "print(\"âœ… Categorized predictions and flagged at-risk orders\")\n",
    "print(f\"\\nðŸ“Š Distribution by Lateness Category:\")\n",
    "print(df_open['lateness_category'].value_counts().sort_index())\n",
    "print(f\"\\nðŸš¨ At-Risk Deliveries (>3 days late): {df_open['at_risk'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e2ef88",
   "metadata": {},
   "source": [
    "### ðŸ’¾ 8. Save Predictions to Lakehouse\n",
    "\n",
    "**Output Table:** `delivery_lateness_predictions`\n",
    "\n",
    "**What's included:**\n",
    "- **Identifiers:** Delivery Number, Customer name\n",
    "- **Order Details:** Priority, Product category\n",
    "- **Dates:** Customer requested date\n",
    "- **Predictions:** AGE_REQ_DATE, ship date, lateness category, risk flags\n",
    "- **Metadata:** Prediction timestamp, model name\n",
    "\n",
    "**Next Steps:**\n",
    "1. Add this table to your Power BI semantic model\n",
    "2. Create relationship: `Aging[Delivery Number]` â†’ `delivery_lateness_predictions[Delivery Number]`\n",
    "3. Build dashboards using prediction columns\n",
    "4. Schedule this notebook to run daily at 6 AM for fresh predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7134925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SAVE TO LAKEHOUSE\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n=== Saving Predictions to Lakehouse ===\")\n",
    "\n",
    "# Select essential columns for Power BI\n",
    "output_cols = [\n",
    "    # Identifiers\n",
    "    'Delivery Number',\n",
    "    'Sold To Name 1',\n",
    "    \n",
    "    # Order details\n",
    "    'Delivery Priority',\n",
    "    'Product Category',\n",
    "    \n",
    "    # Dates\n",
    "    'Req. Date Header',\n",
    "    \n",
    "    # Predictions\n",
    "    'predicted_age_req_date',\n",
    "    'predicted_ship_date',\n",
    "    'lateness_category',\n",
    "    'at_risk'\n",
    "]\n",
    "\n",
    "# Filter to columns that exist\n",
    "available_output_cols = [c for c in output_cols if c in df_open.columns]\n",
    "predictions_df = df_open[available_output_cols].copy()\n",
    "\n",
    "# Add metadata\n",
    "predictions_df['prediction_timestamp'] = datetime.now()\n",
    "predictions_df['model_name'] = MODEL_NAME\n",
    "\n",
    "# Save to Lakehouse table\n",
    "table_name = \"delivery_lateness_predictions\"\n",
    "spark_df = spark.createDataFrame(predictions_df)\n",
    "spark_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"âœ… Saved {len(predictions_df):,} predictions to table: {table_name}\")\n",
    "print(f\"âœ… Columns saved: {len(available_output_cols) + 2}\")\n",
    "print(f\"\\nðŸš¨ At-Risk Summary:\")\n",
    "print(f\"   Total At-Risk Deliveries: {df_open['at_risk'].sum():,} (predicted >3 days late)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491d1fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Predictions Complete!\n",
    "\n",
    "The `delivery_lateness_predictions` table is now available in your Lakehouse and ready for Power BI consumption.\n",
    "\n",
    "**Key Outputs:**\n",
    "- `predicted_age_req_date`: Days late/early vs customer requested delivery date\n",
    "- `predicted_ship_date`: Forecasted ship date (Req. Date + predicted lateness)\n",
    "- `lateness_category`: Simple grouping (Early, On-Time, Late)\n",
    "- `at_risk`: Flag for deliveries predicted >3 days late\n",
    "\n",
    "**Next Steps:**\n",
    "1. **Add to Power BI**: Import `delivery_lateness_predictions` table into your semantic model\n",
    "2. **Create Relationship**: `Aging[Delivery Number]` â†’ `delivery_lateness_predictions[Delivery Number]`\n",
    "3. **Build Dashboards**: Create at-risk delivery views, customer lists, carrier performance reports\n",
    "4. **Automate**: Schedule this notebook to run daily at 6 AM\n",
    "5. **Monitor**: Track prediction accuracy by comparing to actuals weekly\n",
    "6. **Take Action**: Use at-risk data for daily operations standup meetings and proactive customer outreach"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
